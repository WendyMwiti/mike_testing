{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "341cdd2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sense2vecNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading sense2vec-2.0.1-py2.py3-none-any.whl (40 kB)\n",
      "     -------------------------------------- 40.0/40.0 kB 382.1 kB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from sense2vec) (1.21.5)\n",
      "Collecting srsly<3.0.0,>=2.4.0\n",
      "  Downloading srsly-2.4.5-cp39-cp39-win_amd64.whl (481 kB)\n",
      "     ------------------------------------ 481.4/481.4 kB 494.4 kB/s eta 0:00:00\n",
      "Collecting spacy<4.0.0,>=3.0.0\n",
      "  Downloading spacy-3.4.4-cp39-cp39-win_amd64.whl (11.9 MB)\n",
      "     -------------------------------------- 11.9/11.9 MB 222.5 kB/s eta 0:00:00\n",
      "Collecting wasabi<1.2.0,>=0.8.1\n",
      "  Downloading wasabi-1.1.0-py3-none-any.whl (27 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.1\n",
      "  Downloading catalogue-2.0.8-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (5.2.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (2.28.1)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Downloading spacy_loggers-1.0.4-py3-none-any.whl (11 kB)\n",
      "Collecting thinc<8.2.0,>=8.1.0\n",
      "  Downloading thinc-8.1.7-cp39-cp39-win_amd64.whl (1.3 MB)\n",
      "     ---------------------------------------- 1.3/1.3 MB 252.8 kB/s eta 0:00:00\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.9-cp39-cp39-win_amd64.whl (18 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (2.11.3)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4\n",
      "  Downloading pydantic-1.10.4-cp39-cp39-win_amd64.whl (2.1 MB)\n",
      "     ---------------------------------------- 2.1/2.1 MB 209.9 kB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (21.3)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.10\n",
      "  Downloading spacy_legacy-3.0.11-py2.py3-none-any.whl (24 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.7-cp39-cp39-win_amd64.whl (30 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.8-cp39-cp39-win_amd64.whl (96 kB)\n",
      "     -------------------------------------- 96.8/96.8 kB 346.1 kB/s eta 0:00:00\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (63.4.1)\n",
      "Collecting pathy>=0.3.5\n",
      "  Downloading pathy-0.10.1-py3-none-any.whl (48 kB)\n",
      "     -------------------------------------- 48.9/48.9 kB 410.9 kB/s eta 0:00:00\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "     ------------------------------------ 181.6/181.6 kB 391.3 kB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<4.0.0,>=3.0.0->sense2vec) (4.64.1)\n",
      "Collecting typer<0.8.0,>=0.3.0\n",
      "  Downloading typer-0.7.0-py3-none-any.whl (38 kB)\n",
      "Collecting wasabi<1.2.0,>=0.8.1\n",
      "  Downloading wasabi-0.10.1-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<4.0.0,>=3.0.0->sense2vec) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<4.0.0,>=3.0.0->sense2vec) (4.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->sense2vec) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->sense2vec) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->sense2vec) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->sense2vec) (3.3)\n",
      "Collecting blis<0.8.0,>=0.7.8\n",
      "  Downloading blis-0.7.9-cp39-cp39-win_amd64.whl (7.0 MB)\n",
      "     ---------------------------------------- 7.0/7.0 MB 233.0 kB/s eta 0:00:00\n",
      "Collecting confection<1.0.0,>=0.0.1\n",
      "  Downloading confection-0.0.4-py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<4.0.0,>=3.0.0->sense2vec) (0.4.5)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy<4.0.0,>=3.0.0->sense2vec) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jinja2->spacy<4.0.0,>=3.0.0->sense2vec) (2.0.1)\n",
      "Installing collected packages: wasabi, cymem, spacy-loggers, spacy-legacy, pydantic, murmurhash, langcodes, catalogue, blis, typer, srsly, preshed, pathy, confection, thinc, spacy, sense2vec\n",
      "Successfully installed blis-0.7.9 catalogue-2.0.8 confection-0.0.4 cymem-2.0.7 langcodes-3.3.0 murmurhash-1.0.9 pathy-0.10.1 preshed-3.0.8 pydantic-1.10.4 sense2vec-2.0.1 spacy-3.4.4 spacy-legacy-3.0.11 spacy-loggers-1.0.4 srsly-2.4.5 thinc-8.1.7 typer-0.7.0 wasabi-0.10.1\n"
     ]
    }
   ],
   "source": [
    "pip install sense2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e3e57b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sense2vec import Sense2Vec\n",
    "import spacy\n",
    "from sense2vec import Sense2VecComponent\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89330f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_csvs(directory):\n",
    "    dataframes = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            dataframes.append(pd.read_csv(filepath))\n",
    "    return pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "df = read_csvs(\"data\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cff98f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataUnderstanding(object):\n",
    "    \"\"\" Data Understanding class\"\"\"\n",
    "    \n",
    "    def __init__(self, df):\n",
    "        self.shape = df.shape\n",
    "        self.info = df.info\n",
    "        self.duplicates = df.duplicated().sum()\n",
    "        self.missing = df.isna().sum()\n",
    "        self.dtypes = df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91b7925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the class\n",
    "understanding = dataUnderstanding(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a98162",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shape of data\n",
    "print(f'The data has a shape of {understanding.shape[0]} rows and {understanding.shape[1]} columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88641cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary of dataframe\n",
    "understanding.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac25027",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the data types of the data\n",
    "understanding.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3764eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for missing values\n",
    "understanding.missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8994dd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for duplicates\n",
    "understanding.duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad562125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the missing value\n",
    "df.dropna(axis=0, how='any', inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b66ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6d1670",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join the questions and answers column into one column dubbed qa\n",
    "df['qa'] = df['question'].apply(lambda x:str(x)) + '' + df['answer'].apply(lambda x:str(x))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df00fa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the 'qa' column from the 'final' dataframe and convert it to a list\n",
    "df_qalist = df['qa'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7465806c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first 5 elements of the final_qalist list\n",
    "df_qalist[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee040fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of lists where each sublist is a list of words from a document\n",
    "sentence_stream = [doc.split(\" \") for doc in df_qalist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85afa978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first 5 elements of the sentence_stream list\n",
    "sentence_stream[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aece708",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sense2vec import Sense2Vec\n",
    "s2v = Sense2Vec().from_disk(\"C:/Users/User/Documents/Learning Python/finalproject/s2v_reddit_2015_md/s2v_old\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cedd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if the model is working collectly\n",
    "query = \"natural_language_processing|NOUN\"\n",
    "assert query in s2v\n",
    "vector = s2v[query]\n",
    "freq = s2v.get_freq(query)\n",
    "most_similar = s2v.most_similar(query, n=3)\n",
    "most_similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590353fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "spacy.cli.download('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de68d7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_string = ' '.join(map(str, sentence_stream))\n",
    "print(sentence_string) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad3943c",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(sentence_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eebe347",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "#from sense2vec import Sense2VecComponent\n",
    "\n",
    "# Load the spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Add the sense2vec component to the pipeline\n",
    "s2v = Sense2Vec().from_disk(\"C:/Users/User/Documents/Learning Python/finalproject/s2v_reddit_2015_md/s2v_old\")\n",
    "\n",
    "# Process your document\n",
    "doc = nlp(sentence_string)\n",
    "for token in doc: \n",
    "    print(token.text, token.vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f981af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qalist_vector = df_qalist.vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e071c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the tokens\n",
    "for token in doc:\n",
    "    # Get the token's vector\n",
    "    token_vector = token.vector\n",
    "    # Compute the similarity score between the token and the mean vector\n",
    "    similarity = np.dot(doc_vector, token_vector) / (np.linalg.norm(doc_vector) * np.linalg.norm(token_vector))\n",
    "    print(token.text, similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f494725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the target word\n",
    "target_word = nlp(doc)[0]\n",
    "\n",
    "# Iterate over the tokens in the document\n",
    "for token in doc:\n",
    "    # Compare the similarity of the token to the target word\n",
    "    similarity = target_word.similarity(token)\n",
    "    #if the similarity score is above a threshold, then you print the token\n",
    "    if similarity > 0.5:\n",
    "        print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be431049",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f38f61e1f253a75d042c75732b1075763aaf2b6f3c885256756f2d82c9c9fe78"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
